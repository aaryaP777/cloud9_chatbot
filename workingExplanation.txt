chatbot_engine.py

We're doing RAG (Retrieval-Augmented Generation): 

We embed:
ğŸ§¾ Cloud data chunks â†’ input_type="search_document"
â“ User queries â†’ input_type="search_query"

This way, Cohere optimizes embeddings differently:

1. "search_document" tells Cohere: â€œThese are the documents I want to search over.â€
2. "search_query" tells Cohere: â€œThis is a question someone will ask.â€

This combo improves semantic similarity search accuracy â€” a core part of any chatbot using RAG.

ğŸ” So:
You use input_type="search_document" for indexing logs.
And input_type="search_query" for comparing the user's live question.

running:uvicorn app:app --reload --port 8001